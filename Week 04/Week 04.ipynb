{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标\n",
    "### 1.学习使用Jupyter\n",
    "### 2.了解API/JSON, 从在线数据库(twitter, GitHub, weibo, douban等)抓取数据\n",
    "### 3.了解基本文件格式: CSV/JSON\n",
    "   #### 能够掌握好复合结构:比如 {} 和 []\n",
    "   #### 能够良好使用多层的 for循环 和 re-format 数据\n",
    "   #### 能够使用连载器对文件进行输入和输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn to use Jupyter Notebook\n",
    "\n",
    "#### originally called \"IPython notebook\" (interactive Python notebook), so having the .ipynb suffix/ extention name\n",
    "#### provides a web-based interface to interactively test and build Python codes(suited for a bottom-up approach when buiding larger projects)\n",
    "\n",
    "### Virtual environment(虚拟环境)\n",
    "#### \"environment\" refers to the context where the program is executed (The context can be time, operating system, current working folder, Python version, dependent module version(从属模块版本), the status of system, the status of dependent components, ...)\n",
    "\n",
    "#### **TIP**: 环境不同两段代码可以表现地不同\n",
    "#### Python有一个虚拟环境的概念，可以使用虚拟化确保项目在同一类环境中执行(Python2 and Python3 in same computer)  也用虚拟化确定从属Python模块，在*requirements.txt*具体说明\n",
    "\n",
    "#### 两种命令方式建立*virtualenv*\n",
    "   #### *virtualenv* -- old executable usually used in Python2.\n",
    "   #### *pyvenv* -- the default and recommended way of setting up virtualenv in Python3. (安装时已经自带)\n",
    "\n",
    "### Setup virtualenv and install Jupyter Notebook\n",
    "#### 如果出现in [ * ], 可以在kernel目录下，点击stop或者按两次 “ I ”\n",
    "#### Cell目录下，run cell是一步一步运行；run all above是运行和检查之前的所有代码\n",
    "#### Kernel是交互输入或输出从头到尾的所有内容，？点击restart可以赋予变量一个另外的值？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File operation\n",
    "\n",
    "### Write a file\n",
    "#### 1. 创立文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过不同名字可以创立不同的文件，例如*name.txt, name.json*，但不同文件有不同的读写方式\n",
    "#### ‘w’即write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.写内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\",\"w\")\n",
    "\n",
    "f.write('python tutorial')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f.close( )即停止写入，关掉文件并存储\n",
    "#### (文档里出现了一个叫‘text.txt’的文件，并且里面内容为‘python tutorial’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a file\n",
    "\n",
    "#### 首先打开文件，读取内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\", \"r+\")\n",
    "contents = f.read()\n",
    "content = f.read(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‘r’即读取，‘r+’即从头开始读取，如果想要读取？字符串的某一部分，需要使用这种方法？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append( )  追加内容\n",
    "#### 即使附加内容而不是覆盖原文件，要打开原文件，只用在append mode里输入(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = open(\"Hello.txt\", \"a\")\n",
    "h.write(\"Hello World again\")\n",
    "h.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = open(\"Hello.txt\", \"a\")\n",
    "h.write(\", I am coming!\")\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文件内容多了新输入的', I am coming!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV\n",
    "#### CSV (Comma Separated Values) 是电子数据表格(spreadsheets)最常用的输入输出形式 以及 数据库，如‘xlsx’文件\n",
    "#### 使用之前输入*import csv*即可\n",
    "\n",
    "#### CSV有两种基本functions: *reader* and *writer*. 对应读和写\n",
    "\n",
    "\n",
    "### csv.reader\n",
    "#### 返回到reader对象，读取给定的CSV文件；从CSV文件读取的每一排都返回到字符串的一个list；不会自动执行的数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffname', 'id', 'gender', 'location', 'phone']\n",
      "['Chico', '1742', 'M', 'KLN', '3344']\n",
      "['Ri', '1743', 'F', 'LOS', '5168']\n",
      "['Ivy', '1655', 'F', 'MK', '7323']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"chapter4-example-name_list.csv\",\"r\") as f:\n",
    "    rows = csv.reader(f)\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 名字出问题 \\ufeffname\n",
    "#### as ‘f’ 这个‘f’可以随意命名\n",
    "#### for后面的row也是可以随意替换\n",
    "\n",
    "#### Note:\n",
    "#### · *with open(....) as f* 表示给了f一个定义，代表打开文件；‘f’能被任意字符代替，它只意味着你重新命名了打开的这个步骤；它相当于‘ f = open('chapter4-example-name_list.csv',mode='r') ’\n",
    "#### · *open()* 意味着打开文件，如果这里没有相关文件，它会创建一个新的文件；如果已经有存在的文件，写入function会清空之前的所有内容，然后写入新内容\n",
    "#### · 输出结果的开头出现了编译问题，U+FEFF是byte order mark, or BOM(字节顺序标记)，常用于区别编译‘big-’ 和 ‘little-endian’(字节存储顺序) UTF-16. 为了删掉BOM，只需要在‘with....open’里增加一个编译线*with open('chapter4-example-name_list.csv',encoding='utf-8-sig') as f:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'id', 'gender', 'location', 'phone']\n",
      "['Chico', '1742', 'M', 'KLN', '3344']\n",
      "['Ri', '1743', 'F', 'LOS', '5168']\n",
      "['Ivy', '1655', 'F', 'MK', '7323']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"chapter4-example-name_list.csv\",encoding='utf-8-sig') as f:\n",
    "    rows = csv.reader(f)\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv.writer\n",
    "#### 返回一个写入对象将用户的数据转换成限定的字符串。CSV可以通过*write()*方法成为任何对象。如果CSV是文件对象，它打开的方式应该为 *newline=''* , 如果* newline=' ' * 没有具体说明，插入引用段的newlines将不会被正确解释；所以需要具体说明‘ newline=' ' ’，因为csv模块有自己的处理newline的方式。\n",
    "\n",
    "### Write row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('name.csv','w',newline='') as z:\n",
    "    mywriter=csv.writer(z)\n",
    "    mywriter.writerow(['Zach','Male'])\n",
    "    mywriter.writerow(['Pig','Animal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "#### ‘w’代表写入，如果想要读取，则相应输入‘r’.\n",
    "#### ‘csv.writer( )’代表写入一些内容在‘name.csv’的文件里\n",
    "#### ‘writerow( )’代表写入一排，再写入另一排；输入的应该是list类型。\n",
    "#### ‘writerows( )’代表写入一排以后继续写入，知道循环list中的所有元素。\n",
    "#### ‘writerow( )’里的arguments(参数)应该是一个list，因为csv function把row当做一个list，因此需要用[ ] 包裹参数。\n",
    "\n",
    "### Write rows\n",
    "\n",
    "#### 方法1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mylist=[['HKG',1000,3332],['KLT',1001,2333]]\n",
    "with open('location.csv','w',newline='') as z:\n",
    "    mywriter=csv.writer(z)\n",
    "    mywriter.writerows(mylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "number_list = [11,22,33,44,55,66]\n",
    "with open('number.csv','w',newline='') as x:\n",
    "    mywriter=csv.writer(x)\n",
    "    for i in number_list:\n",
    "        mywriter.writerow([i])\n",
    "    \n",
    " ##也可以用writerows来代替 #mywriter.writerows([i]for i in number_list)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么列表是纵向的不是横向的\n",
    "#### [11,22,33,44,55,66] 是一个list，如果是[[11],[22],[33],[44],[55],[66]]这样的，则表示在一排里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_list = ['Zach','Pig','Zeng','Xing','Jie']\n",
    "with open('student.csv','w',newline='') as j:\n",
    "    writer=csv.writer(j)\n",
    "    for j in range(0,len(student_list)):\n",
    "        writer.writerow(student_list[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "#### ‘writerows( )’代表一次性写入所以rows。它写入list中的每一项到一个row里。\n",
    "#### ‘csv.writerow’把row看作是一个list，如上，它把第一排的‘Zach’作为5个字符的list或者strings；接着把它们放入5个cells里。那么，怎样避免把一个字符串的5个characters分别放入不同的cells里？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_list = ['Zach','Pig','Zeng','Xing','Jie']\n",
    "with open('student.csv','w',newline='') as j:\n",
    "    writer=csv.writer(j,delimiter=' ')\n",
    "    for j in range(0,len(student_list)):\n",
    "        writer.writerow(student_list[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‘ delimiter=' ' ’ 两个' '之间一定要有空格！才能被识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "#### 1.Write row ['hello','python'] in A1 in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_python = ['hello','python']\n",
    "with open('hello_python.csv','w',newline='') as z:\n",
    "    writer=csv.writer(z,delimiter=' ')\n",
    "    writer.writerow(hello_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模板答案(两个值被分在了不同的cell)——同样，增加了‘ delimiter=' ' ’后即可出现在一个cell里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('hello.csv','w') as f:\n",
    "    mywriter=csv.writer(f,delimiter=' ')\n",
    "    mywriter.writerow(['hello','python'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Use writerows to write [['spam','1'],['22','333'],['OK','Good']] in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "spam = [['spam','1'],['22','333'],['OK','Good']]\n",
    "with open('spam.csv','w',newline='') as j:\n",
    "    writer=csv.writer(j)\n",
    "    writer.writerows(spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "#### JSON (JavaScript Object Notation) 是一个轻量数据交换格式，通过JavaScript句法引出\n",
    "\n",
    "#### JSON是一个存储和交换数据的句法\n",
    "#### JSON是文本(text)，伴随JavaScript对象注解写入\n",
    "\n",
    "### JSON啥样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstName': 'Jane',\n",
       " 'lastName': 'Doe',\n",
       " 'hobbies': ['running', 'sky diving', 'singing'],\n",
       " 'age': 35,\n",
       " 'children': [{'firstName': 'Alice', 'age': 6},\n",
       "  {'firstName': 'Bob', 'age': 8}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'firstName': \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么要使用JSON？\n",
    "\n",
    "#### JSON的优势:\n",
    "##### 1.数据规模小。相较于XML文件类型去存储和交换数据，JSON的数据规模小，传输速度更快\n",
    "##### 2.传输速度快\n",
    "##### 3.数据格式简单，方便读和写，格式也是压缩过的\n",
    "##### 4.方便在python中使用，JSON是k-v structure的一种形式\n",
    "\n",
    "#### 简单来说，JSON是一个dict，包含keys，每一个key相对应一个value。中间被‘ : ’分开，最外层被‘ { } ’包裹，而不同的‘key-value’组又被‘ , ’给分开\n",
    "\n",
    "#### 例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果一个key相对应多个values，那么用‘ [ ] ’来包括相应的values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': ['v11', 'v12', 'v13'], 'key2': 'v22'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'key1': ['v11', 'v12', 'v13'], 'key2': 'v22'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON functions\n",
    "\n",
    "#### json.dumps: Serialize object to a JSON formatted str (连载对象到一个JSON模式的字符串)\n",
    "#### 句法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e02726bd3312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "json.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=\"utf-8\", default=None, sort_keys=False, **kw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上述的参数并不会都使用到，一般来说用这两个：\n",
    "#### 1.如果 ‘ sort_keys ’ 是ture(默认是:False)，那么dictionaries的输出将通过key被存储\n",
    "#### 2.如果 ‘ ensure_ascii ’ 是ture(默认)，那么输出将确保有所有新到的non-ASCII字符，除了像中文字符这样的。如果 ‘ ensure_ascii ’ 是false，这些字符将被输出为-is\n",
    "\n",
    "##### 把Python object data 变成 JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name' : 'AMG',\n",
    "    'shares' : 100,\n",
    "    'price' : 233.33\n",
    "}\n",
    "json_str = json.dumps(data)\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果想要存储JSON字符串到一个文件里，让其他人能够再利用它，可以用*open( )  with the .write( )* function 来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_data.json', \"w\") as f:\n",
    "    f.write(json_data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIP: 在Jupyter里，可以在‘ ! ’之后写入shell commands。‘ cat ’本质上是一个读取文件内容并输出到屏幕的shell command。它是一种常用语检查输出结果是否为想要的结果的方式。在week01中，我们学习了几种有用的命令，比如‘ cd ’，‘ pwd ’和‘ ls ’，这些命令也能在这里使用，也能让我们回想起如何在Jupyter里安装新的Python modules：‘ !pip install <package-name> ’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_data.json', \"w\") as f:\n",
    "    f.write(json_data)\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json.loads: Deserialize JSON str to a Python object\n",
    "\n",
    "#### 句法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(s, *, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从句法上分析JSON string 到 Python内在数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = '''\n",
    "{\n",
    "    \"dataset\": {\n",
    "        \"train\": { \"type\": \"mnist\", \"data_set\": \"train\", \"layout_x\": \"tensor\" },\n",
    "        \"test\": { \"type\": \"mnist\", \"data_set\": \"test\", \"layout_x\": \"tensor\" }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "import json\n",
    "result = json.loads(json_str)\n",
    "result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 上述没反应\n",
    "\n",
    "#### TIP: 当在Python里写入大量的数据，这个\"multi-line string\"(多线程字符串), \"block string literal\"(逐字翻译区块字符串-翻译不来看英文), or \"verbatim\"(一字不差)就很有用了。它能帮助在数据里保留所有形式，像缩进等等。这个特点在几乎所有编程语言中都有，它的官方名字叫作: *HEREDOC*\n",
    "\n",
    "#### 在上述的例子里，可以从一个文件中使用‘ .read( ) the json_str ’ 而不是HEREDOC\n",
    "\n",
    "#### 输出: ‘ result ’的内容 ？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'dataset': {'test': {'data_set': 'test',\n",
    "   'layout_x': 'tensor',\n",
    "   'type': 'mnist'},\n",
    "  'train': {'data_set': 'train', 'layout_x': 'tensor', 'type': 'mnist'}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json.load & json dump\n",
    "\n",
    "#### 事实上，我们想在json文件和Python对象之间转换，我们可以直接使用*json.load & json.dump*。‘ loads ’和‘ load ’或者‘ dumps ’ 及‘ dump ’的不同在于通过 *-s* 方法可以得到字符串。有时候，我们这些字符串去做其他事情，而不仅仅只是写入文件。？？？？\n",
    "\n",
    "#### 在JSON文件和Python对象之间转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu = {\n",
    "    \"age\": 20,\n",
    "    \"score\": 88,\n",
    "    \"name\": \"Bob\"\n",
    "}\n",
    "with open('stu.json', 'w') as f:\n",
    "    json.dump(stu, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stu.json', 'r') as f:\n",
    "     data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "\n",
    "#### Requests是用来爬网站和得到数据最主要的module\n",
    "\n",
    "### Make a Request\n",
    "#### 执行一个request很简单:\n",
    "#### 首先，在import之前，使用‘ pip ’安装requests\n",
    "#### 然后，import *requests* modules\n",
    "#### 通常使用 *requests.get* 去为数据执行request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://www.imdb.com/list/ls058982125/')\n",
    "#r_str = r.text\n",
    "r_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 现在，我们有了一个叫作‘ r ’的Response对象。能从这个对象中得到所有想要的信息(有关2017电影的列表)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Content\n",
    "\n",
    "#### 在得到Response对象‘ r ’后，需要读取服务器response的内容，这里有三种方法去读取内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://www.imdb.com/list/ls058982125/')\n",
    "r.text\n",
    "r.json\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.如果想要返回到文本数据，使用*r.text* (最常使用)\n",
    "#### 2.如果想要返回到JSON，使用*r.json*\n",
    "#### 3.如果想要回到图片和文件，使用*r.content*，它会返回到binary(二进制的)数据 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "#### Application Program Interfaces(应用程序交互界面)，或APIs，常用于从远端网站retrieve(提取/取出)数据。像Twitter，Douban甚至政府网站都会通过它们的APIs提供特定数据。为了使用API，需要向远端网站服务器make a request，然后提取想要的数据。\n",
    "\n",
    "### Why use api\n",
    "#### 相较于其他如直接下载等方式，APIs在下列案例中更实用:\n",
    "#### 1.数据变更非常快。不需要你每分钟去重新下载数据，这种方式会使用很大的bandwidth(带宽)，也非常慢；而从API得到的数据总是最新的(除非特别设定)\n",
    "#### 2.通常，从APIs返回的数据组能够直接转换到CSV和JSON，显得更结构化和清晰，相较于‘ .html ’不用花太多时间去清理和找数据。\n",
    "#### 3.可以根据需求过滤数据，而不用下载大量数据\n",
    "\n",
    "#### 通常，不同网站有不同的APIs来获取数据。比如， USGS和Douban的APIs是一个‘ url ’，可以在这个‘ url ’里改变一些参数来获取不同的数据；然而Twitter的API是一套tokens和keys，可以调用不同的functions去获取数据\n",
    "\n",
    "\n",
    "### Use API via HTTP request/ response\n",
    "#### 在下面这个例子中，会被质疑一个简单的API去提取有关过去100年在台湾发生地震的数据\n",
    "\n",
    "#### 第一步: 找到它的API, 读取它的文件\n",
    "#### API link: https://earthquake.usgs.gov/fdsnws/event/1/\n",
    "#### 不同的机构和网站有它们自己使用API的规则，对于这个地震API，不能够从原始的API链接里请求到所有数据，需要特定到某个地区，以及想要的哪一个时间段。就像是表明什么内容或数据是需要请求的。接着便可以通过这些参数到原API链接中请求相应数据。(可以点击上面链接查看相关例子)\n",
    "\n",
    "#### 第二步:  设定我们想要使用的arguments和functions\n",
    "#### Functions: (1) query?  \n",
    "####                    (2) count?\n",
    "\n",
    "#### Arguments: (1) Start time: 1918-08-24\n",
    "####                      (2) End time: 2018-08-24\n",
    "####                      (3) Min latitude: 21.890\n",
    "####                      (4) Min longitude: 119.300\n",
    "####                      (5) Max latitude: 25.320\n",
    "####                      (6) Max longitude: 122.030\n",
    "\n",
    "#### 第三步:  创建我们想要的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "api_url = 'https://earthquake.usgs.gov/fdsnws/event/1/'\n",
    "api_method1 = 'query?'\n",
    "api_method2 = 'count?'\n",
    "api_format = 'format=geojson'\n",
    "api_starttime = '1918-08-24'\n",
    "api_endtime = '2018-08-24' \n",
    "api_minlatitude = '21.890'\n",
    "api_minlongitude = '119.300'\n",
    "api_maxlatitude = '25.320'\n",
    "api_maxlongitude = '122.030'\n",
    "\n",
    "query_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method1,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n",
    "count_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method2,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### endtime: 如果想要返回的数据是更新到目前的时间，只用去掉endtime就好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第四步:  Requests内容\n",
    "#### 如果只想知道过去一百年发生了多少次地震，只需使用*count_url*，它将返回得到了多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 3946, 'maxAllowed': 20000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "api_url = 'https://earthquake.usgs.gov/fdsnws/event/1/'\n",
    "api_method1 = 'query?'\n",
    "api_method2 = 'count?'\n",
    "api_format = 'format=geojson'\n",
    "api_starttime = '1918-08-24'\n",
    "api_endtime = '2018-08-24' \n",
    "api_minlatitude = '21.890'\n",
    "api_minlongitude = '119.300'\n",
    "api_maxlatitude = '25.320'\n",
    "api_maxlongitude = '122.030'\n",
    "\n",
    "query_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method1,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n",
    "count_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method2,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n",
    "\n",
    "response = requests.get(count_url)\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最后的data相当于print(data)\n",
    "#### Note: 注意在Jupyter里，不能通过直接使用其本身名字而删掉 'print( )' \n",
    "\n",
    "#### 如果只想要所有数据并提取关键信息，使用*query_url*就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=1918-08-24&minlatitude=21.890&maxlatitude=25.320&minlongitude=119.300&maxlongitude=122.030'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "api_url = 'https://earthquake.usgs.gov/fdsnws/event/1/'\n",
    "api_method1 = 'query?'\n",
    "api_method2 = 'count?'\n",
    "api_format = 'format=geojson'\n",
    "api_starttime = '1918-08-24'\n",
    "api_endtime = '2018-08-24' \n",
    "api_minlatitude = '21.890'\n",
    "api_minlongitude = '119.300'\n",
    "api_maxlatitude = '25.320'\n",
    "api_maxlongitude = '122.030'\n",
    "\n",
    "query_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method1,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n",
    "count_url ='{0}{1}{2}&starttime={3}&minlatitude={4}&maxlatitude={5}&minlongitude={6}&maxlongitude={7}'.format(api_url,api_method2,api_format,api_starttime,api_minlatitude,api_maxlatitude,api_minlongitude,api_maxlongitude)\n",
    "\n",
    "response = requests.get(query_url)\n",
    "data = response.json()\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第五步:  选择想要的key values: mag(震级), place和time, 然后写入csv文件里\n",
    "#### 可以检查返回的JSON，最外层是一个dict，想要的所有key information都在key features里，同时，这里也有很多features。所以首先，应该通过使用数据 ['features'] 提取所有features，它会返回一个包含所有features的list。接着在这个list里，每一次地震的信息在一个dict里。所以，能进一步使用keys去获取它的values。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TTT.csv','w',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = ['place','mag','time','felt']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for i in range(0,len(data['features'])):\n",
    "        writer.writerow([data['features'][i]['properties']['place'],\n",
    "                         data['features'][i]['properties']['mag'],\n",
    "                         data['features'][i]['properties']['time'],\n",
    "                         data['features'][i]['properties']['rms']])\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # data['features'][i]['properties']['mag'] 意思是找出所有地震的震级(magnitude)\n",
    "    # data['features'][i]['properties']['place'] 意思是找到所有地点\n",
    "    # data['features'][i]['properties']['time'] 意思是找出所以时间\n",
    "    \n",
    "#### Quiz: You can see that the time is not what we want. Can you convert them to UTC time(Universal Time Coordinated).？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不使用Python来测试API\n",
    "\n",
    "#### 注意 *requests.get(url)* 从根本来说发送一个 *GET HTTP* 的请求到服务器。通过此即可不使用Python。网页浏览器，比如Google Chrome每天发送许多 *GET* 请求到访问的网站。可以使用 *print(url)* 去得到最终组合的URL，然后复制粘贴这个URL到浏览器的地址框，去测试从服务器的回应。因为大多数API都是返回到JSON数据结构，可以在Google Chrome里使用JSONView扩展名去得到一个更好的视野和更简单地探索回应。\n",
    "\n",
    "\n",
    "### 通过function来使用API唤起其他的modules/ packages\n",
    "\n",
    "#### 另一个值得介绍的API方法是使用给到的‘ keys ’和‘ token ’，通过它们建立的能够使用的function去获取数据。但是这个方法的一个缺点是能得到的数据数量很有限。拥有很大数据库的公司对此都非常严格。在这个例子中，将继续使用台湾的例子，在关键字“Taiwan earthquake”下去抓取用户推特。\n",
    "\n",
    "#### 第一步:  检查并安装“python-twitter”\n",
    "#### Python twitter是一个为Twitter API提供纯粹Python交互界面的library。它在Python2.7+和Python3中使用。\n",
    "#### 通常，使用Jupyter去练习和pip的方式去安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二步:  获取应用tokens\n",
    "\n",
    "#### 为了使用python-twitter API客户端，首先需要去获取一组应用tokens。当开始申请的时候，consumer_key和consumer_secret被传授给*twitter.Api()* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='8oJUIL1lPFTTQMPwCvQjV1RwK',\n",
    "                  consumer_secret='9NGMoUChIkHsftkylsbSo6005dlmYIaKXmbHgPeLCd28scVJVO',\n",
    "                 access_token_key='1047386128108507136-iIpX4BoWySlv2KC3hUcrHXCF7BI72G',\n",
    "                 access_token_secret='hRSeHoTOJh53wMJYxSFCYPTH00mAasFBh25vqpkdcgeZG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import csv\n",
    "api = twitter.Api(consumer_key=\"8oJUIL1lPFTTQMPwCvQjV1RwK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第三步: 找到正确的function去唤起\n",
    "\n",
    "    这里有许多functions去完成不同的需求。如果想要\n",
    "There are many functions to accomplish different demands. If you want to get status from one given twitter ID, api.GetUserTimeline is the right one. As for our example, we should use api.GetSearch to get the comments. Then change the parameters we want. For more functions, please see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           keywords in all files\n",
      "china                         93\n",
      "trade                         58\n",
      "chinese                       51\n",
      "war                           38\n",
      "trump                         32\n",
      "beijing                       25\n",
      "tariffs                       22\n",
      "would                         22\n",
      "said                          20\n",
      "more                          18\n",
      "against                       16\n",
      "president                     15\n",
      "america                       15\n",
      "american                      14\n",
      "deal                          14\n",
      "CPU times: user 69.2 ms, sys: 4.32 ms, total: 73.5 ms\n",
      "Wall time: 76.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "import os #用於讀取文件列表\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "pd.set_option('max_rows',2000)\n",
    "pd.set_option('max_colwidth',100)\n",
    "punctuation += '\\\"“”‘’—-–'\n",
    "\n",
    "def list_documents(path): #將待處理的文件以list輸出\n",
    "    list_txt = []\n",
    "    list_file = os.listdir(path)\n",
    "    list_file.remove('stopword.txt')\n",
    "    for i in list_file:\n",
    "        if i.find('.txt') != -1:\n",
    "            list_txt.append(i)\n",
    "    list_txt.sort()\n",
    "    n = len(list_txt)\n",
    "    return list_txt, n #n是文件數量\n",
    "\n",
    "def kill_punctuations_capitals(text): #將大寫字母轉化為小寫，去除標點，列出單詞\n",
    "    text = text.replace(\"’s\",\"\")\n",
    "    translator = str.maketrans(\"\",\"\",punctuation) \n",
    "    #translator = str.maketrans(punctuation,len(punctuation)*' ') #note:str.maketrans(input,output,delete)\n",
    "    list_lowercase_without_punctuation = text.lower().translate(translator).split()\n",
    "    return list_lowercase_without_punctuation\n",
    "    \n",
    "\n",
    "def extract_meaningful(list): #去除無意義的單詞\n",
    "    list_meaningful_words = []\n",
    "    with open ('stopword.txt','r') as s:\n",
    "        list_stop_words = s.read().split() #讀取stoplist\n",
    "    for m in list:\n",
    "        if m not in list_stop_words:\n",
    "            list_meaningful_words.append(m)\n",
    "    return list_meaningful_words\n",
    "    \n",
    "def words_frequency(list): #統計一篇文章中的frequency\n",
    "    dict_words_frequency={}\n",
    "    for m in list:\n",
    "        dict_words_frequency[m]=list.count(m)\n",
    "    return dict_words_frequency\n",
    "\n",
    "def update_dict(dict0,dict1): #兩個txt中的frequency相加\n",
    "    for k,v in dict1.items():\n",
    "        if dict0.__contains__(k):\n",
    "            dict0[k] += v\n",
    "        else:\n",
    "            dict0.update({k : dict1[k]})\n",
    "\n",
    "def rank_frequency(dict): #根據frequency排序，也可以最後用print(s.sort_values(ascending=False))，但是不方便寫cvs\n",
    "    dict_frequency_rank={}\n",
    "    rank = sorted(dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    for m in range(0,len(rank)):\n",
    "        dict_frequency_rank.update({rank[m][0]:rank[m][1]})\n",
    "    return dict_frequency_rank\n",
    "\n",
    "def write_cvs(dict):\n",
    "    with open('keywords_frequency.csv','w',newline='') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        header = ['keyword','frequency']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(dict.items())\n",
    "path = \"./\"\n",
    "list_txt,n = list_documents(path)\n",
    "dict_accumulative_frequency = {}\n",
    "dict_list_frequency = {}\n",
    "for i in list_txt:\n",
    "    with open(i,'r') as t:\n",
    "        text = t.read()\n",
    "    dict_list_frequency[i] = rank_frequency(words_frequency(extract_meaningful(kill_punctuations_capitals(text))))\n",
    "    update_dict(dict_accumulative_frequency,dict_list_frequency[i])\n",
    "\n",
    "dict_frequency_rank = rank_frequency(dict_accumulative_frequency)\n",
    "write_cvs(dict_frequency_rank)\n",
    "    \n",
    "print(pd.DataFrame({'keywords in all files':pd.Series(dict_frequency_rank)}).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:china\n",
      "                                                                                     paragraphs\n",
      "trade-wars-news1.txt                                           [2, 3, 5, 7, 18, 22, 24, 25, 28]\n",
      "trade-wars-news2.txt  [0, 2, 3, 4, 5, 6, 8, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26]\n",
      "trade-wars-news3.txt                   [0, 3, 7, 8, 14, 17, 18, 20, 21, 24, 25, 27, 30, 31, 37]\n",
      "trade-wars-news4.txt                                          [0, 3, 4, 18, 19, 20, 27, 28, 29]\n",
      "trade-wars-news5.txt              [2, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "CPU times: user 7.99 ms, sys: 2.65 ms, total: 10.6 ms\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "def list_documents(path): #將待處理的文件以list輸出\n",
    "    list_txt = []\n",
    "    list_file = os.listdir(path)\n",
    "    list_file.remove('stopword.txt')\n",
    "    for i in list_file:\n",
    "        if i.find('.txt') != -1:\n",
    "            list_txt.append(i)\n",
    "    list_txt.sort()\n",
    "    n = len(list_txt)\n",
    "    return list_txt, n #n是文件數量\n",
    "def locate_word(word,text):\n",
    "    list_paragraphs_contain_word = []\n",
    "    list_paragraphs_text = text.lower().split('\\n')\n",
    "    while '' in list_paragraphs_text:\n",
    "        list_paragraphs_text.remove('')\n",
    "    for i in range(0,len(list_paragraphs_text)):\n",
    "        if list_paragraphs_text[i].find(word) > -1:\n",
    "            list_paragraphs_contain_word.append(i)\n",
    "    return list_paragraphs_contain_word\n",
    "\n",
    "word = input('word:')\n",
    "path = \"./\"\n",
    "list_txt, n = list_documents(path)\n",
    "dict_words_location = {}\n",
    "for i in list_txt:\n",
    "    with open(i,'r') as t:\n",
    "        text = t.read()\n",
    "    dict_words_location[i] = locate_word(word,text)\n",
    "\n",
    "data=pd.Series(dict_words_location)\n",
    "print(pd.DataFrame({'paragraphs':data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
